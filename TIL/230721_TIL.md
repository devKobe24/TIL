# Section II: Grand Central Dispatch 👀</br>

---

## 5. Concurrency Problems

불행히도 디스패치 큐가 제공하는 모든 이점에도 불구하고 모든 성능 문제에 대한 만병통치약은 아닙니다.
주의하지 않으면 앱에서 동시성을 구현할 때 발생할 수 있는 세 가지 잘 알려진 문제가 있습니다.

- Race conditions
- Deadlock
- Priority inversion(우선순위 역전)

### Race conditions(경쟁 조건) 🤔</br>

앱 자체를 포함하여 동일한 프로세스를 공유하는 스레드는 동일한 주소 공간을 공유합니다.
이것이 의미하는 바는 각 스레드가 동일한 공유 리소스를 읽고 쓰려고 한다는 것입니다.
주의하지 않으면 여러 스레드가 동시에 동일한 변수에 쓰려고 시도하는 **race conditions** 에 빠질 수 있습니다.

실행 중인 두 개의 스레드가 있고 둘 다 개체의 `count` 변수를 업데이트하려고 하는 예를 고려하십시오.
읽기와 쓰기는 컴퓨터가 단일 작업으로 실행할 수 없는 별도의 작업입니다.
컴퓨터는 클록의 각 틱이 단일 작업을 실행을 허용하는 **clock cycles(클록 주기)** 로 작동합니다.

> 📌 참고 : 컴퓨터의 clock cycle와 시계의 clock을 혼동하지 마십시오.</br>
> iPhone XS에서는 2.49GHz 프로세서가 탑재되어 있어 초당 2,490,000,000 클럭 사이클을 수행할 수 있습니다!</br>

스레드 1과 스레드 2는 모드 카운트를 업데이트하기를 원하므로 다음과 같이 멋진 코드를 작성합니다.

```swift!
count += 1
```

꽤 무해한 것 같죠?
해당 문장을 구성 요소로 나누고 약간의 손짓을 추가하면 다음과 같은 문장이 완성됩니다.

1. 변수 `count`의 값을 메모리에 로드합니다.
2. 메모리에서 `count` 값을 하나씩 증가시킵니다.
3. 새로 업데이트된 `count`를 다시 디스크에 씁니다.

<img src = "https://github.com/devKobe24/images/blob/main/raceCondition.png?raw=true"></br>

위 그림은 다음을 보여줍니다.

- 스레드 1은 스레드 2보다 먼저 clock cycle(클럭 주기)를 시작하고 `count`에서 값 `1`을 읽습니다.
- 두 번째 clock cycle(클럭 주기)에서 스레드 1은 메모리 내 값을 `2`로 업데이트하고 스레드 2는 `count`에서 값 `1`을 읽습니다.
- 세 번째 clock cycle(클럭 주기)에서 스레드 1은 이제 값 `2`를 `count` 변수에 다시 씁니다. 그러나 스레드 2는 이제 메모리 내 값을 `1`에서 `2`로 업데이트하고 있습니다.
- 네 번째 clock cycle(클럭 주기)에서 스레드 2도 값 `2`를 `count`에 기록합니다. 두 개의 개별 스레드가 둘 다 값을 업데이트 했디 때문에 값 `3`을 볼 것으로 예상한 경우를 제외하고 말입니다.

이러한 유형의 race condition은 이러한 시나리오의 비결정적 특성으로 인해 매우 복잡한 디버깅으로 이어집니다.

스레드 1이 단지 2개의 clock cycle(클록 주기)를 일찍 시작한 경우 예상한 대로 값 `3`을 갖게 되지만 이러한 clock cycle(클록 주기)가 초당 몇 번 발생하는지는 잊지 마십시오.

프로그램을 20번 실행하고 올바른 결과를 얻은 다음 배포하고 버그 보고서를 받기 시작할 수 있습니다.

race conditions(경쟁 조건)이 발생하고 있다는 것을 알고 있는 한 일반적으로 직렬 대기열(serial queue)을 사용하여 경쟁 조건을 해결할 수 있습니다.

프로그램에 동시에 액세스해야 하는 변수가 있는 경우 다음과 같이 private queue로 읽기 및 쓰기를 래핑할 수 있습니다.

```swift!
private let threadSafeCountQueue = DispatchQueue(label: "...")
private let _count = 0
private var count: Int {
    get {
        return threadSafeCountQueue.sync {
            _count
        }
    }
    set {
        threadSafeCountQueue.sync {
            _count = newValue
        }
    }
}
```

달리 명시하지 않았기 때문에 threadSafeCountQueue는 직렬 대기열입니다.

이는 한 번에 하나의 작업만 시작할 수 있음을 의미합니다.
따라서 변수에 대한 액세스를 제어하고 한 번에 하나의 스레드만 변수에 액세스할 수 있도록 합니다.
위와 같이 간단한 읽기/쓰기를 수행하는 경우 이것이 최상의 솔루션입니다.

> 📌 참고: 여러 스레드에 대해 실행될 수 있는 지연 변수(lazy variables)에 대해 동일한 private queue 동기화를 구현할 수 있습니다.</br>
> 그렇지 않으면 지연 변수(lazy variables) 이니셜라이저의 두 인스턴스가 실행될 수 있습니다.</br>
> 이전의 변수 할당과 마찬가지로 두 스레드는 거의 동일한 시간에 지연 변수(lazy variables)에 액세스를 시도할 수 있습니다.</br>
> 일단 두 번째 스레드가 지연 변수(lazy variables)에 접근을 시도하면 아직 초기화되지 않았지만 첫 번째 스레드의 접근에 의해 생성될 예정입니다.</br>
> 고전적인 경쟁 조건(race condition)입니다.</br>

### Thread barrier 🤔</br>

경우에 따라 공유 리소스에는 단순한 변수 수정보다 getter 및 setter에 더 복잡한 논리가 필요합니다.
온라인에서 이와 관련된 질문을 자주 볼 수 있으며 종종 locks 및 semaphores와 관련된 솔루션과 함께 제공됩니다.
Locking은 제대로 구현하기가 매우 어렵습니다.
대신 GCD에서 Apple의 dispatch barrier 솔루션을 사용할 수 있습니다.

동시 대기열(concurrent queue)을 생성하면 동시에 실행할 수 있는 만큼 읽기 유형 작업을 원하는 만큼 처리할 수 있습니다.

변수를 작성해야 하는 경우 이미 제출된 모든 항목이 완료되지만 업데이트가 완료될 때까지 새 체줄이 실행되지 않도록 대기열을 잠가야 합니다.

다음과 같은 방식으로 Dispatch barrier 접근 방식(approach)을 구현합니다.

```swift!
private let threadSafeCountQueue = DispatchQueue(label: "...",
                                                attributes: .concurrent)

private vat _count = 0
public var count: Int {
    get {
        return threadSafeCountQueue.sync {
            return _count
        }
    }
    set {
        threadSafeCountQueue.async(flags: .barrier) { [unowned self] in 
            self._count = newValue
        }
    }
}
```

이제 동시 대기열을 원하고 쓰기가 barrier으로 구현되어야 함을 지정하는 방법에 주목하십시오
barrier 작업은 이전의 모든 읽기가 완료될 때까지 발생하지 않습니다.

barrier에 도달하면 대기열은 직렬(serial)인 것처럼 가장하고 완료될 때까지 장벽 작업만 실행할 수 있습니다.
완료되면 barrier 작업 이후에 제출된 모든 작업이 다시 동시에 실행 될 수 있습니다.

### Deadlock 🤔</br>

화창한 날 2차선 도로를 운전하여 목적지에 도착했다고 상상해 보십시오.
목적지가 길 건너편에 있으므로 차의 방향 지시등을 켭니다.
수많은 트래픽이 다른 방향으로 운전할 때 기다립니다.

기다리는 동안 뒤에 다섯 대의 차가 줄을 섭니다.
그런 다음 방향 지시등을 켜고 다른 방향으로 오는 자동차를 발견하고 몇 대의 자동차도 정지하지만 이제 백업에 의해 차단됩니다.

불행하게도 다가오는 차량 뒤에 더 많은 차량이 있어 다른 차선도 후진하여 목적지로 방향을 전환하고 차선을 비울 수 없습니다.

둘 다 결코 완료할 수 없는 다른 작업을 기다리고 있으므로 이제 deadlock(교착 상태)에 도달했습니다.
자동차가 목적지 입구를 막고 있기 때문에 어느 쪽도 회전할 수 없습니다.

<img src = "https://github.com/devKobe24/images/blob/main/deadlock.png?raw=true"></br>

Deadlock(교착 상태)는 semaphores 또는 기타 명시작 locking 메커니즘과 같은 것을 사용하지 않는 한 Swift 프로그래밍에서 매우 드물게 발생합니다.

현재 디스패치 큐에 대해 실수로 `sync`를 호출하는 것은 가장 흔히 발생하는 일입니다.

semaphores를 사용하여 여러 리소스에 대한 액세스를 제어하는 경우 동일한 순서로 리소스를 요청해야 합니다.
스레드 1이 망치를 요청한 다음 톱을 요청하고 스레드 2가 톱과 망치를 요청하면 deadlock(교착 상태)가 발생할 수 있습니다.

스레드 1은 망치를 요청하고 받는 동시에 스레드 2는 톱을 요청하고 받습니다.
그런 다음 스레드 1은 망치를 놓지 않고 톱을 요청하지만 스레드 2는 리소스를 소유하므로 스레드 1은 기다려야 합니다.

스레드 2는 톱을 요청하지만 스레드 1은 여전히 리소스를 소유하고 있으므로 스레드 2는 톱을 사용할 수 있을때까지 기다려야 합니다.

요청된 리소스가 해제될 때까지 둘 다 진행할 수 없기 때문에 두 스레드는 이제 deadlock(교착 상태)에 있으며, 이는 결코 발생하지 않습니다.

### Priority inversion(우선순위 역전) 🤔</br>

기술적으로 말해서 **priority inversion(우선순위 역전)** 은 낮은 서비스 품질의 대기열이 높은 **quality of service(서비스 품질)**(QoS)의 queue보다 **system priority(시스템 우선 순위)** 가 높을 때 발생합니다.

작업을 대기열에 제출하는 작업을 해 본 적이 있다면 `qos` 매개변수를 사용하는 `async` 생성자를 보았을 것입니다.

3장 "Queues & Threads"에서 큐에 제출된 작업에 따라 큐의 QoS가 변경될 수 있다고 언급했습니다.
일반적으로 작업을 대기열에 제출하면 작업이 대기열 자체의 우선 순위(priority)를 갖습니다.
그러나 필요한 경우 특정 작업의 우선 순위가 보통보다 높거나 낮도록 지정할 수 있습니다.

`.userInitiated` 대기열과 `.utility` 대기열을 사용하는 경우, 후자의 대기열에 여러 작업을 `.userInteractive` 서비스 품질(`.userInitiated` 보다 우선 순위가 높음)로 제출하면 운영 체제에서 후자의 대기열에 더 높은 우선 순위가 할당되는 상황에 처할 수 있습니다.

갑지기 대기열의 모든 작업(대부분 실제로는 `.utility` 서비스 품질에 속하는 작업)이 `.userInitiated` 대기열의 작업보다 먼저 실행되게 됩니다.

이것은 피하기 쉽습니다. 더 높음 품질의 서비스가 필요하다면 다른 대기열을 이용하십시오!

우선 순위 역전(Priority inversion)이 발생하는 보다 일반적인 상황은 서비스 품질이 높은 큐가 서비스 품질이 낮은 큐와 리소스를 공유하는 경우입니다.

하위 큐가 객체를 잠그면 상위 큐는 이제 기다려야 합니다.
잠금이 해제될 때까지 우선순위가 높은 대기열은 낮은 우선순위 작업이 실행되는 동안 아무 작업도 수행하지 않는 상태입니다.

실제로 priority inversion을 확인하려면 이 장의 프로젝트 자료에 있는 **starter** 프로젝트 폴터에서 **PriorityInversion.playground** 라는 플레이그라운드를 엽니다.

코드에서 QoS 값이 다른 세 개의 스레드와 세마포어를 볼 수 있습니다.

```swift!
let high = DispatchQueue.global(qos: .userInteractive)
let medium = DispatchQueue.global(qos: .userInitiated)
let low = DispatchQueue.global(qos: .background)

let semaphore = DispatchSemaphore(value: 1)
```

그런 다음 모든 대기열에서 다양한 작업이 시작됩니다.

```swift!
high.async {
    // Wait 2 seconds just to be sure all the other tasks have enqueued
    // 다른 모든 작업이 대기열에 추가되었는지 확인하기 위해 2초 동안 기다립니다.
    Thread.sleep(forTimeInterval: 2)
    semaphore.wait()
    defer { semaphore.signal() }
    
    print("High priority task is now running")
}

for i in 1...10 {
    medium.async {
        let waitTime = Double(exactly: arc4random_uniform(7))!
        print("Running medium task \(i)")
        Thread.sleep(forTimeInterval: waitTime)
    }
}

low.async {
    semaphore.wait()
    defer { semaphore.signal() }
    
    print("Running long, lowest priority task")
    Thread.sleep(forTimeInterval: 5)
}
```

콘솔(⇧ + ⌘ + Y)을 표시한 다음 플레이그라운드를 실행하면 실행할 때마다 다른 순서가 표시됩니다.

```swift!
Running medium task 7
Running medium task 6
Running medium task 1
Running medium task 4
Running medium task 2
Running medium task 8
Running medium task 5
Running medium task 3
Running medium task 9
Running medium task 10
Running long, lowest priority task
High priority task is now running
```

최종 결과는 항상 동일합니다.
high-priority(높은 우선순위) 태스크는 priority inversion(우선순위 역전)으로 인해 항상 중간(medium) 및 낮은 우선순위(low-priority) 태스크 이후에 실행됩니다.
